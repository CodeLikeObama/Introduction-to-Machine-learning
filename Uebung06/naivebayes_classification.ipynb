{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_dataset_pandas(dataset_path):\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    X = df.iloc[:, 0].to_numpy()\n",
    "    y = df.iloc[:, 1].to_numpy()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(X_train, X_test):\n",
    "    \"\"\"Vectorizes a training and a test set via term frequency - inverse document frequency \n",
    "    (TF-IDF). The function receives two lists of strings, X_train and X_test, that contain \n",
    "    the text data for each sample in the training and test set, respectively. The function\n",
    "    trains the TF-IDF procedure (using the sklearn default arguments!), applies it to the\n",
    "    data and returns V_train and V_test, which contains the vectorized data for the training\n",
    "    and test set, respectively.\"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    # train tf-idf vectorizer\n",
    "        # HINT: On which data sets should the IDF be calculated\n",
    "        # to prevent data leakage?\n",
    "    # transform X_train\n",
    "    # transform X_test\n",
    "    # return them\n",
    "\n",
    "    return V_train, V_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_classifier_and_predict(V_train, y_train, V_test):\n",
    "    \"\"\"Fits a naive bayes classifier to the already vectorized data. The function takes two\n",
    "    design matrices V_train and V_test and the true labels belonging to the data points in \n",
    "    V_train. The function fits a naive bayes classifier to the training data and predicts\n",
    "    the labels of the test data. The function returns the trained classifier and the predicted\n",
    "    labels on the test data.\"\"\"\n",
    "\n",
    "    # TODO:\n",
    "    # Fit a Naive Bayes ClassiÔ¨Åer\n",
    "    # Make a prediction of the text text\n",
    "\n",
    "    return classifier, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(y_true, y_pred, pos_label=1, neg_label=0):\n",
    "    \"\"\"Calculates the confusion matrix between the true labels y_true\n",
    "    and the predicted labels y_pred of an array. For this it needs to\n",
    "    know the label of the positive class pos_class.\n",
    "    The function assumes that there are only 2 classes.\n",
    "    Returns the true positive, false positive, false negative and\n",
    "    true negative values as floats or numpy values in this specific\n",
    "    order.\"\"\"\n",
    "\n",
    "    # TODO\n",
    "    # calculate the confusion matrix given the true and predicted labels\n",
    "    # if possible, use vectorized operations and numpy internal functions\n",
    "    # Remember, you may not use scikit-learn\n",
    "\n",
    "    return true_pos, false_pos, false_neg, true_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_pos, false_pos, false_neg, true_neg, pos_label=1, neg_label=0):\n",
    "    \"\"\"Plots the confusion matrix between the truth and prediction.\n",
    "    For this, the function needs the values of the confusion matrix as well as the name\n",
    "    of the positive and negative label for a better visualization. Otherwise default\n",
    "    values are used (1 and 0 for positive / negative). \n",
    "    \"\"\"\n",
    "\n",
    "    confusion_mat = np.array([[true_pos, false_neg], [false_pos, true_neg]])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8.27, 8.27))\n",
    "    sns.heatmap(confusion_mat, ax=ax, square = True, annot=True, fmt = \"d\", xticklabels=[pos_label, neg_label], yticklabels=[pos_label, neg_label])\n",
    "    ax.set_xlabel(\"Prediction\", fontsize=16)\n",
    "    ax.set_ylabel(\"Truth\", fontsize=16)\n",
    "    plt.show()\n",
    "    \"\"\"Plots the confusion matrix between the truth and prediction.\"\"\"\n",
    "\n",
    "    # TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20newsgroups dataset - multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# create a hold out test set\n",
    "# vectorize the data\n",
    "# fit a classifier\n",
    "# compute the accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spam - No spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# create a hold out test set\n",
    "# vectorize the data\n",
    "# fit a classifier\n",
    "# calculate the confusion matrix\n",
    "# plot the confusion matrix\n",
    "# compute accuracy of the prediction and precision, recall, and f1 for both classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
